name: "XR08 - add_attachment_to_test_step: Handle invalid step_id (Negative Test)"
description: |
  Verify the Xray 'add_attachment_to_test_step' tool properly handles invalid step_id formats.

  Objective: Test error handling for invalid step_id parameter

  Expected Behavior (NEGATIVE TEST):
  - Tool returns error for invalid step_id
  - Error message mentions step_id validation
  - Error message suggests using get_tests to retrieve step IDs
  - No test modification occurs
  - Proper error handling without crashing

toolkits:
  - id: ${XRAY_TOOLKIT_ID}
    name: ${XRAY_TOOLKIT_NAME}

state:
  project_key:
    type: str
    value: ${XRAY_PROJECT_KEY:EL}
  invalid_step_id:
    type: str
    value: "INVALID-123"
  attachment_content:
    type: str
    value: "Test attachment content"
  attachment_filename:
    type: str
    value: "test_file.txt"
  add_attachment_result:
    type: str
  expected_error_indicators:
    type: list
    value: ["Tool execution error", "invalid", "doesn't exist", "does not exist", "not found", "UUID", "get_tests"]
  unexpected_success_indicators:
    type: list
    value: ["Successfully added attachment", "File size"]
  test_results:
    type: dict

entry_point: add_attachment_with_invalid_step_id
nodes:
  - id: add_attachment_with_invalid_step_id
    type: toolkit
    input:
      - invalid_step_id
      - attachment_content
      - attachment_filename
    input_mapping:
      step_id:
        type: variable
        value: invalid_step_id
      filedata:
        type: variable
        value: attachment_content
      filename:
        type: variable
        value: attachment_filename
    output:
      - add_attachment_result
    structured_output: false
    tool: add_attachment_to_test_step
    toolkit_name: ${XRAY_TOOLKIT_NAME}
    continue_on_error: true
    transition: validate_error_handling

  - id: validate_error_handling
    type: llm
    input:
      - add_attachment_result
      - invalid_step_id
      - unexpected_success_indicators
      - expected_error_indicators
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a strict quality assurance validator. Only return valid JSON.
      task:
        type: fstring
        value: |
          Validate negative test: add_attachment_to_test_step with invalid step_id.
          
          Result: {add_attachment_result}
          Expected errors: {expected_error_indicators}
          Unexpected success: {unexpected_success_indicators}

          This NEGATIVE test PASSES if:
          1. Result is NOT empty (length > 10)
          2. Result contains error indicators
          3. Result does NOT contain success indicators

          Return JSON:
          {{
            "test_passed": boolean,
            "tool_executed": true,
            "has_error_message": boolean,
            "error_message_meaningful": boolean,
            "no_success_indicators": boolean,
            "error_indicator_found": "string"
          }}

          Return ONLY the JSON object.
    model: ${DEFAULT_LLM_MODEL}
    output:
      - test_results
    structured_output_dict:
      test_results: dict
    transition: END
