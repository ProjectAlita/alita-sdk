name: "GH06 - File Operations Workflow"
description: "Test file lifecycle: create_file, read_file to verify, apply_git_patch to modify, read_file to verify patch, delete_file, cleanup"

toolkits:
  - id: ${GITHUB_TOOLKIT_ID}
    name: ${GITHUB_TOOLKIT_NAME}

state:
  input:
    type: str
  messages:
    type: list
  branch_name_base:
    type: str
    value: "test/gh9-file-ops"
  branch_name:
    type: str
  file_path:
    type: str
  file_contents:
    type: str
  tool_result:
    type: str
  read_result:
    type: str
  patch_content:
    type: str
  commit_message:
    type: str
  patched_content:
    type: str
  validation_results:
    type: dict
  test_results:
    type: dict

entry_point: prepare_test_data

nodes:
  # Step 1: Prepare unique branch and file names
  - id: prepare_test_data
    type: code
    code:
      type: fixed
      value: |
        import time
        import random
        import string

        # Generate unique identifiers
        timestamp = time.strftime('%Y%m%d-%H%M%S')
        random_suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=4))

        # Branch name
        base_branch = alita_state.get('branch_name_base', 'test/gh9-file-ops')
        branch_name = f"{base_branch}-{timestamp}-{random_suffix}"

        # File path and initial content
        file_path = f"test-data/generated/file-ops-{timestamp}-{random_suffix}.txt"
        nl = chr(10)
        file_contents = f"# File Operations Test{nl}Created at: {timestamp}{nl}Random ID: {random_suffix}{nl}This file tests create_file and apply_git_patch."

        {"branch_name": branch_name, "file_path": file_path, "file_contents": file_contents}
    input:
      - branch_name_base
    output:
      - branch_name
      - file_path
      - file_contents
    structured_output: true
    transition: create_branch

  # Step 2: Create test branch
  - id: create_branch
    type: toolkit
    tool: create_branch
    toolkit_name: ${GITHUB_TOOLKIT_NAME}
    input:
      - branch_name
    input_mapping:
      proposed_branch_name:
        type: variable
        value: branch_name
    output:
      - tool_result
    structured_output: true
    transition: set_active_branch

  # Step 3: Set the new branch as active
  - id: set_active_branch
    type: toolkit
    tool: set_active_branch
    toolkit_name: ${GITHUB_TOOLKIT_NAME}
    input:
      - branch_name
    input_mapping:
      branch_name:
        type: variable
        value: branch_name
    output:
      - tool_result
    structured_output: true
    transition: create_file

  # Step 4: Create the test file
  - id: create_file
    type: toolkit
    tool: create_file
    toolkit_name: ${GITHUB_TOOLKIT_NAME}
    input:
      - file_path
      - file_contents
    input_mapping:
      file_path:
        type: variable
        value: file_path
      file_contents:
        type: variable
        value: file_contents
    output:
      - tool_result
    structured_output: true
    transition: read_file_after_create

  # Step 5: Read the file to verify it was created (optional due to GitHub API propagation delay)
  - id: read_file_after_create
    type: toolkit
    tool: read_file
    toolkit_name: ${GITHUB_TOOLKIT_NAME}
    input:
      - file_path
    input_mapping:
      file_path:
        type: variable
        value: file_path
    output:
      - read_result
    structured_output: true
    continue_on_error: true
    transition: validate_create

  # Step 6: Validate file creation with LLM
  - id: validate_create
    type: llm
    model: gpt-4o
    input:
      - file_path
      - file_contents
      - read_result
    input_mapping:
      system:
        type: fixed
        value: "You are a quality assurance validator."
      task:
        type: fstring
        value: |
          Analyze the file creation operation results.

          Expected File Path: {file_path}
          Expected File Contents: {file_contents}
          Read Result: {read_result}

          Perform the following checks (NOTE: read may fail due to GitHub API propagation delay - this is acceptable):

          1. Check if the file was read successfully (read_result is not empty or null and does not contain "File not found")
          2. If read succeeded, verify the read content matches the expected file contents (exact match or contains the key lines)
          3. If read succeeded, check if the original content is preserved correctly

          Return a JSON object named validation_results with the following structure:

          {{
            "create_file_ok": boolean (true if file was created - may be unknown if read failed),
            "content_matches": boolean (true if content matches expected, or null if read failed),
            "original_length": integer (length of expected content),
            "read_length": integer (length of read content, or 0 if read failed),
            "error": string or null (error message if any),
            "failed_checks": list of strings (failed checks if any - empty if read failed due to propagation delay)
          }}

          Return **EXACTLY** **NONNEGOTIATABLE** only the `validation_results` JSON object. Do not use markdown ```json when returning the json. Do not include any explanations, summaries, or additional text.
      chat_history:
        type: fixed
        value: []
    output:
      - validation_results
    structured_output_dict:
        validation_results: "dict"
    transition: prepare_patch

  # Step 6b: Prepare git patch
  - id: prepare_patch
    type: code
    code:
      type: fixed
      value: |
        import time
        import random
        import string

        file_path = alita_state.get('file_path')
        file_contents = alita_state.get('file_contents', '')

        # Prepare git patch to add new lines to the file
        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
        random_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=4))

        nl = chr(10)
        # Create patch that adds lines to the end of the file
        # Count original lines for the patch header
        original_lines = file_contents.split(nl)
        line_count = len(original_lines)

        patch_content = f"diff --git a/{file_path} b/{file_path}" + nl
        patch_content += f"--- a/{file_path}" + nl
        patch_content += f"+++ b/{file_path}" + nl
        patch_content += f"@@ -{line_count},0 +{line_count},3 @@" + nl
        patch_content += f"+{nl}"
        patch_content += f"+# Patch Applied{nl}"
        patch_content += f"+Patched at: {timestamp} - ID: {random_id}"

        commit_message = f"GH9 patch test {random_id}"

        # Expected content after patch
        patched_content = f"Patch Applied"

        {"patch_content": patch_content, "commit_message": commit_message, "patched_content": patched_content}
    input:
      - file_path
      - file_contents
    output:
      - patch_content
      - commit_message
      - patched_content
    structured_output: true
    transition: apply_git_patch

  # Step 7: Apply git patch to modify the file
  - id: apply_git_patch
    type: toolkit
    tool: apply_git_patch
    toolkit_name: ${GITHUB_TOOLKIT_NAME}
    input:
      - patch_content
      - commit_message
    input_mapping:
      patch_content:
        type: variable
        value: patch_content
      commit_message:
        type: variable
        value: commit_message
    output:
      - tool_result
    structured_output: true
    transition: read_file_after_patch

  # Step 8: Read file again to verify patch was applied
  - id: read_file_after_patch
    type: toolkit
    tool: read_file
    toolkit_name: ${GITHUB_TOOLKIT_NAME}
    input:
      - file_path
    input_mapping:
      file_path:
        type: variable
        value: file_path
    output:
      - read_result
    structured_output: true
    transition: process_results

  # Step 9: Validate patch application with LLM
  - id: process_results
    type: llm
    model: gpt-4o
    input:
      - file_path
      - file_contents
      - read_result
      - patched_content
      - tool_result
      - validation_results
    input_mapping:
      system:
        type: fixed
        value: "You are a quality assurance validator."
      task:
        type: fstring
        value: |
          Analyze the complete file operations workflow results.

          File Path: {file_path}
          Original File Contents: {file_contents}
          File After Patch: {read_result}
          Expected Patch Content: {patched_content}
          Patch Tool Result: {tool_result}
          Create Validation Results: {validation_results}

          Perform the following checks:

          1. Check if the patch tool executed successfully (tool_result not empty/null)
          2. Confirm the patch content "{patched_content}" exists in the file after patching
          3. Verify the original content is still preserved in the patched file
          4. Check if the file grew in size after patching (final_length > original_length)

          NOTE: The initial read_file_verify_create may have failed due to GitHub API propagation delay. 
          This is acceptable as long as the patch operation succeeded, which proves the file was created.

          Return a JSON object named test_results with the following structure:

          {{
            "test_passed": boolean (true if patch operations succeeded - create_file is validated by patch success),
            "operations": {{
              "create_file": boolean (true if patch succeeded, proving file exists),
              "read_file_verify_create": boolean (from validation_results, may be false due to propagation delay),
              "apply_git_patch": boolean,
              "read_file_verify_patch": boolean
            }},
            "details": {{
              "file_path": string,
              "original_content_length": integer,
              "final_content_length": integer,
              "patch_content_found": boolean,
              "original_preserved": boolean
            }},
            "error": string or null (error message if any),
            "failed_checks": list of strings (failed checks if any - exclude read_file_verify_create failures)
          }}

          Return **EXACTLY** **NONNEGOTIATABLE** only the `test_results` JSON object. Do not use markdown ```json when returning the json. Do not include any explanations, summaries, or additional text.
      chat_history:
        type: fixed
        value: []
    output:
      - test_results
    structured_output_dict:
        test_results: "dict"
    transition: delete_file

  # Step 10: Delete the test file
  - id: delete_file
    type: toolkit
    tool: delete_file
    toolkit_name: ${GITHUB_TOOLKIT_NAME}
    input:
      - file_path
    input_mapping:
      file_path:
        type: variable
        value: file_path
    output:
      - tool_result
    structured_output: true
    transition: delete_branch

  # Step 11: Delete the test branch
  - id: delete_branch
    type: toolkit
    tool: delete_branch
    toolkit_name: ${GITHUB_TOOLKIT_NAME}
    input:
      - branch_name
    input_mapping:
      branch_name:
        type: variable
        value: branch_name
      force:
        type: fixed
        value: true
    output:
      - tool_result
    structured_output: true
    transition: END
