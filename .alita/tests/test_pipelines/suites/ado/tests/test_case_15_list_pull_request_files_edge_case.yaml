name: "ADO15 - list_pull_request_files: Handle invalid PR ID"
description: |
  Verify the ADO 'list_pull_request_files' tool handles invalid PR ID gracefully.

  Objective: Test error handling for non-existent PR

  Expected Behavior:
  - Tool handles invalid PR ID gracefully
  - Returns error message or empty result
  - Does not crash

toolkits:
  - id: ${ADO_REPOS_TOOLKIT_ID}
    name: ${ADO_REPOS_TOOLKIT_NAME}

state:
  pull_request_id:
    type: str
    value: "999999"
  expected_error_indicators:
    type: list
    value: ["not found", "does not exist", "error", "null", "None", "404", "[]"]
  tool_result:
    type: str
  test_results:
    type: dict

entry_point: invoke_list_pull_request_files
nodes:
  - id: invoke_list_pull_request_files
    type: toolkit
    input:
      - pull_request_id
    input_mapping:
      pull_request_id:
        type: variable
        value: pull_request_id
    output:
      - tool_result
    structured_output: true
    tool: list_pull_request_files
    toolkit_name: ${ADO_REPOS_TOOLKIT_NAME}
    transition: validate_results

  - id: validate_results
    type: llm
    input:
      - tool_result
      - pull_request_id
      - expected_error_indicators
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a strict quality assurance validator. Only return valid JSON.
      task:
        type: fstring
        value: |
          Analyze the output from the 'list_pull_request_files' tool with INVALID PR ID.

          Tool Result: {tool_result}
          Invalid PR ID Used: {pull_request_id}
          Expected Error Indicators: {expected_error_indicators}

          This is a NEGATIVE test - we expect the tool to handle invalid input gracefully.

          Validation Criteria (ALL must pass):
          1. tool_executed: Tool ran without crashing (got some result)
          2. graceful_handling: Output contains error indicator, empty list, or null
          3. no_unhandled_exception: Output does NOT contain 'unhandled', 'traceback', 'stack trace'

          Return a JSON object with structure:
          {{
            "test_passed": boolean (true only if ALL criteria pass),
            "tool_executed": boolean,
            "graceful_handling": boolean,
            "no_unhandled_exception": boolean,
            "error_indicator_found": "which indicator was found or 'none'",
            "error": string | null
          }}

          Return ONLY the JSON object (no markdown or explanation).
    model: ${DEFAULT_LLM_MODEL}
    output:
      - test_results
    structured_output_dict:
      test_results: dict
    transition: END
