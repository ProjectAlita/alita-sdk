name: "QT12 - find_test_runs_by_test_case_id: Find test runs for test case"
description: |
  Verify the QTest 'find_test_runs_by_test_case_id' tool finds test runs associated with a test case.

  Objective: Test retrieval of execution history (test runs) for a test case

  Expected Behavior:
  - Query executes without errors
  - Returns list of test runs (if any exist)
  - Response contains test run fields (Id, Name, Status)
  - Handles test cases with no runs gracefully
  - No error indicators in output (excluding Status field values)

toolkits:
  - id: ${QTEST_TOOLKIT_ID}
    name: ${QTEST_TOOLKIT_NAME}

state:
  project_id:
    type: int
    value: ${QTEST_PROJECT_ID}
  test_case_id:
    type: str
  dql_query:
    type: str
  search_result:
    type: str
  find_test_runs_result:
    type: str
  expected_success_indicators:
    type: list
    value: ["test runs", "TR-", "Id", "Name"]
  error_indicators:
    type: list
    value: ["error", "exception"]
  test_results:
    type: dict

entry_point: find_existing_test_case
nodes:
  - id: find_existing_test_case
    type: code
    code:
      type: fixed
      value: |
        # Search for any existing test case to use for the query
        dql_query = "Status is 'not empty'"
        {"dql_query": dql_query}
    input:
      - project_id
    output:
      - dql_query
    structured_output: true
    transition: search_test_cases

  - id: search_test_cases
    type: toolkit
    input:
      - dql_query
    input_mapping:
      dql:
        type: variable
        value: dql_query
    output:
      - search_result
    structured_output: false
    tool: search_by_dql
    toolkit_name: ${QTEST_TOOLKIT_NAME}
    transition: extract_test_case_id

  - id: extract_test_case_id
    type: code
    code:
      type: fixed
      value: |
        import re
        
        # Extract first test case ID from search results
        result_str = alita_state.get("search_result", "")
        test_case_id = "TC-1"  # fallback
        
        try:
            # Look for TC-xxx pattern
            match = re.search(r"(TC-\d+)", result_str)
            if match:
                test_case_id = match.group(1)
        except Exception:
            pass
        
        {"test_case_id": test_case_id}
    input:
      - search_result
    output:
      - test_case_id
    structured_output: true
    transition: find_test_runs

  - id: find_test_runs
    type: toolkit
    input:
      - test_case_id
    input_mapping:
      test_case_id:
        type: variable
        value: test_case_id
    output:
      - find_test_runs_result
    structured_output: false
    tool: find_test_runs_by_test_case_id
    toolkit_name: ${QTEST_TOOLKIT_NAME}
    transition: validate_results

  - id: validate_results
    type: llm
    input:
      - find_test_runs_result
      - test_case_id
      - expected_success_indicators
      - error_indicators
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a strict quality assurance validator. Only return valid JSON.
      task:
        type: fstring
        value: |
          Analyze the output from the 'find_test_runs_by_test_case_id' tool execution.

          Find Test Runs Result: {find_test_runs_result}
          Test Case ID: {test_case_id}
          Expected Success Indicators: {expected_success_indicators}
          Error Indicators: {error_indicators}

          This is a POSITIVE test - we expect successful execution.

          IMPORTANT: The word "Failed" or "Passed" appearing as a STATUS FIELD VALUE 
          in test run data is NOT an error - it's valid test execution status.
          Only flag actual error messages like "error", "exception", "failed to execute".

          Validation Criteria (ALL must pass for test_passed=true):
          1. tool_executed: Tool ran without throwing an exception
          2. no_errors: Output does NOT contain actual error indicators (error, exception)
          3. has_valid_response: Response structure is valid (list or JSON)
          4. graceful_handling: Empty results are handled gracefully (not an error)
          5. mentions_defects_hint: Response mentions how to find defects via test runs

          NOTE: Empty results (no test runs) are still considered SUCCESS
          as long as the query executed properly and provided helpful guidance.

          Return JSON test_results:
          {{
            "test_passed": boolean (true only if ALL criteria pass),
            "tool_executed": boolean,
            "no_errors": boolean,
            "has_valid_response": boolean,
            "graceful_handling": boolean,
            "mentions_defects_hint": boolean,
            "has_test_runs": boolean (true if test runs found, false if empty),
            "test_runs_count": integer (0 if none found),
            "success_indicator_found": "which indicator was found or 'none'",
            "error_indicator_found": "which error indicator was found or 'none'",
            "error": string | null
          }}

          Return ONLY the JSON object.
    model: ${DEFAULT_LLM_MODEL}
    output:
      - test_results
    structured_output_dict:
      test_results: "dict"
    transition: end

  - id: end
    type: end
