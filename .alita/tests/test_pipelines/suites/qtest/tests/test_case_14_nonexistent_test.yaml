name: "QT14 - find_test_case_by_id: Handle non-existent test case (Negative Test)"
description: |
  Verify the QTest 'find_test_case_by_id' tool properly handles requests for non-existent test cases.

  Objective: Test error handling when querying a test case ID that doesn't exist

  Expected Behavior (NEGATIVE TEST):
  - Tool returns empty result for non-existent test case
  - Response indicates 0 test cases found
  - Proper handling without crashing
  - No test case data is returned

toolkits:
  - id: ${QTEST_TOOLKIT_ID}
    name: ${QTEST_TOOLKIT_NAME}

state:
  project_id:
    type: int
    value: ${QTEST_PROJECT_ID}
  nonexistent_test_id:
    type: str
    value: "TC-999999999"
  find_result:
    type: str
  empty_result_indicators:
    type: list
    value: ["Found 0", "[]", "empty"]
  unexpected_success_indicators:
    type: list
    value: ["QTest Id", "Name", "Description", "Steps"]
  test_results:
    type: dict

entry_point: find_nonexistent_test_case
nodes:
  - id: find_nonexistent_test_case
    type: toolkit
    input:
      - nonexistent_test_id
    input_mapping:
      test_id:
        type: variable
        value: nonexistent_test_id
    output:
      - find_result
    structured_output: false
    tool: find_test_case_by_id
    toolkit_name: ${QTEST_TOOLKIT_NAME}
    transition: validate_error_handling

  - id: validate_error_handling
    type: llm
    input:
      - find_result
      - nonexistent_test_id
      - empty_result_indicators
      - unexpected_success_indicators
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a strict quality assurance validator. Only return valid JSON.
      task:
        type: fstring
        value: |
          Analyze the output from the 'find_test_case_by_id' tool execution.
          
          This is a NEGATIVE test - we EXPECT an empty result for non-existent test case.

          Find Result: {find_result}
          Non-existent Test ID Used: {nonexistent_test_id}
          Empty Result Indicators: {empty_result_indicators}
          Unexpected Success Indicators: {unexpected_success_indicators}

          Validation Criteria (ALL must pass for test_passed=true):
          1. tool_executed: Tool was called successfully
          2. returns_empty_result: Output indicates 0 test cases found or empty list
          3. no_test_data: Output does NOT contain actual test case data (QTest Id, Name, Description, Steps)
          4. no_success_indicators: Output does NOT contain test case field data
          5. graceful_handling: Tool handled non-existent ID gracefully without exception

          Return JSON test_results:
          {{
            "test_passed": boolean (true only if ALL criteria pass - proper empty result handling),
            "tool_executed": boolean,
            "returns_empty_result": boolean,
            "no_test_data": boolean,
            "no_success_indicators": boolean,
            "graceful_handling": boolean,
            "empty_indicator_found": "which empty indicator was found or 'none'",
            "unexpected_success_found": "which success indicator was found or 'none' (should be 'none')",
            "error": string | null
          }}

          Return ONLY the JSON object.
    model: ${DEFAULT_LLM_MODEL}
    output:
      - test_results
    structured_output_dict:
      test_results: "dict"
    transition: end

  - id: end
    type: end
