name: "GH03 - Issue Workflow"
description: "Test issue operations: create issue, list issues, get issue, add various comment types, close issue"


toolkits:
  - id: ${GITHUB_TOOLKIT_ID}
    name: ${GITHUB_TOOLKIT_NAME}


state:
  code_comment:
    type: str
  input:
    type: str
  issue_body:
    type: str
  issue_details:
    type: str
  issue_number:
    type: str
  issue_title:
    type: str
  issues_list:
    type: str
  markdown_comment:
    type: str
  messages:
    type: list
  plain_comment:
    type: str
  test_results:
    type: dict
  tool_result:
    type: str
  validation_results:
    type: dict


entry_point: prepare_test_data


nodes:
  - id: prepare_test_data
    type: llm
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a test data generator for software testing.
      task:
        type: fixed
        value: |
          Generate test data for a GitHub issue workflow test.

          I need the following strings generated:
          1. issue_title: A unique title like "[Test] GH3 Issue Workflow - {Timestamp} - {RandomID}"
          2. issue_body: A comprehensive body text explaining this is an automated test.
          3. plain_comment: A simple plain text comment string.
          4. code_comment: A comment string containing a Python code block and a JavaScript code block.
          5. markdown_comment: A comment string containing a Markdown table and a checklist.

          Make them realistic and varied.
    model: gpt-4o
    output:
      - issue_title
      - issue_body
      - plain_comment
      - code_comment
      - markdown_comment
    structured_output: true
    structured_output_dict:
      code_comment: str
      issue_body: str
      issue_title: str
      markdown_comment: str
      plain_comment: str
    transition: create_issue


  - id: create_issue
    type: toolkit
    input:
      - issue_title
      - issue_body
    input_mapping:
      body:
        type: variable
        value: issue_body
      title:
        type: variable
        value: issue_title
    output:
      - tool_result
    structured_output: true
    tool: create_issue
    toolkit_name: testing
    transition: extract_issue_number


  - id: extract_issue_number
    type: llm
    input:
      - tool_result
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a data extractor. Your job is to parse API responses.
      task:
        type: fstring
        value: |
          Analyze the following result from a create_issue operation:
          {tool_result}

          1. Extract the issue number (as a string).
          2. Create a validation_results dictionary with key "issue_created" set to true if the issue number was found, else false.

          Return issue_number and validation_results.
    model: gpt-4o
    output:
      - issue_number
      - validation_results
    structured_output: true
    structured_output_dict:
      issue_number: str
      validation_results: dict
    transition: list_issues

  - id: list_issues
    type: toolkit
    input: []
    input_mapping:
      state:
        type: fixed
        value: open
    output:
      - issues_list
    structured_output: true
    tool: get_issues
    toolkit_name: testing
    transition: validate_list_issues
    
  - id: validate_list_issues
    type: llm
    input:
      - issues_list
      - issue_number
      - validation_results
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a test validator.
      task:
        type: fstring
        value: |
          I have a list of issues and an issue number I expect to be in it.

          Issue Number: {issue_number}
          Issues List: {issues_list}
          Current Validation Results: {validation_results}

          1. Check if the issue_number is present in the issues_list.
          2. Count the number of issues in the list.
          3. Update validation_results with:
             - "issues_listed": true if count > 0
             - "issue_in_list": true if issue_number is found
             - "issues_count": the count of issues

          Return the updated validation_results.
    model: gpt-4o
    output:
      - validation_results
    structured_output: true
    structured_output_dict:
      validation_results: dict
    transition: get_issue


  - id: get_issue
    type: toolkit
    input:
      - issue_number
    input_mapping:
      issue_number:
        type: variable
        value: issue_number
    output:
      - issue_details
    structured_output: true
    tool: get_issue
    toolkit_name: testing
    transition: validate_get_issue


  - id: validate_get_issue
    type: llm
    input:
      - issue_details
      - issue_number
      - issue_title
      - validation_results
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a test validator.
      task:
        type: fstring
        value: |
          Verify the retrieved issue details match expectations.

          Issue Number: {issue_number}
          Expected Title: {issue_title}
          Retrieved Details: {issue_details}
          Current Validation Results: {validation_results}

          1. Verify if the retrieved details correspond to the issue number (look for the number in the details).
          2. Verify if the title in details matches (or contains) the expected title.
          3. Update validation_results with:
             - "issue_retrieved": true if verification passes
             - "title_matches": true if title matches

          Return the updated validation_results.
    model: gpt-4o
    output:
      - validation_results
    structured_output: true
    structured_output_dict:
      validation_results: dict
    transition: add_plain_comment


  - id: add_plain_comment
    type: toolkit
    input:
      - issue_number
      - plain_comment
    input_mapping:
      comment:
        type: variable
        value: plain_comment
      issue_number:
        type: variable
        value: issue_number
    output:
      - tool_result
    structured_output: true
    tool: comment_on_issue
    toolkit_name: testing
    transition: validate_plain_comment
  - id: validate_plain_comment
    type: llm
    input:
      - tool_result
      - validation_results
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a test validator.
      task:
        type: fstring
        value: |
          Validate if the comment was added successfully based on this tool result:
          {tool_result}

          Current Validation Results: {validation_results}

          Update validation_results with "comment_plain": true if successful.
          Return updated validation_results.
    model: gpt-4o
    output:
      - validation_results
    structured_output: true
    structured_output_dict:
      validation_results: dict
    transition: add_code_comment


  - id: add_code_comment
    type: toolkit
    input:
      - issue_number
      - code_comment
    input_mapping:
      comment:
        type: variable
        value: code_comment
      issue_number:
        type: variable
        value: issue_number
    output:
      - tool_result
    structured_output: true
    tool: comment_on_issue
    toolkit_name: testing
    transition: validate_code_comment

  - id: validate_code_comment
    type: llm
    input:
      - tool_result
      - validation_results
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a test validator.
      task:
        type: fstring
        value: |
          Validate if the code comment was added successfully based on this tool result:
          {tool_result}

          Current Validation Results: {validation_results}

          Update validation_results with "comment_code": true if successful.
          Return updated validation_results.
    model: gpt-4o
    output:
      - validation_results
    structured_output: true
    structured_output_dict:
      validation_results: dict
    transition: add_markdown_comment


  - id: add_markdown_comment
    type: toolkit
    input:
      - issue_number
      - markdown_comment
    input_mapping:
      comment:
        type: variable
        value: markdown_comment
      issue_number:
        type: variable
        value: issue_number
    output:
      - tool_result
    structured_output: true
    tool: comment_on_issue
    toolkit_name: testing
    transition: validate_markdown_comment
  - id: validate_markdown_comment
    type: llm
    input:
      - tool_result
      - validation_results
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a test validator.
      task:
        type: fstring
        value: |
          Validate if the markdown comment was added successfully based on this tool result:
          {tool_result}

          Current Validation Results: {validation_results}

          Update validation_results with "comment_markdown": true if successful.
          Return updated validation_results.
    model: gpt-4o
    output:
      - validation_results
    structured_output: false
    structured_output_dict:
      validation_results: dict
    transition: process_results
  - id: process_results
    type: llm
    input:
      - issue_number
      - validation_results
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a quality assurance reporter.
      task:
        type: fstring
        value: |
          Analyze the final validation results for the Issue Workflow test.

          Issue Number: {issue_number}
          Validation Results: {validation_results}

          Calculate the following statuses based on validation_results:
          - create_issue: result of 'issue_created'
          - list_issues: result of 'issues_listed'
          - get_issue: result of 'issue_retrieved'
          - issues_count: value of 'issues_count' (default 0)
          - plain_text: result of 'comment_plain'
          - code_block: result of 'comment_code'
          - markdown_table: result of 'comment_markdown'

          Logic:
          - all_comments_ok = plain_text AND code_block AND markdown_table
          - all_operations_ok = create_issue AND list_issues AND get_issue AND all_comments_ok

          Construct a final test_results object strictly following this structure:
          {
              "test_passed": all_operations_ok,
              "issue_number": "{issue_number}",
              "operations": {
                  "create_issue": create_issue,
                  "list_issues": list_issues,
                  "get_issue": get_issue,
                  "issues_count": issues_count
              },
              "comments": {
                  "plain_text": plain_text,
                  "code_block": code_block,
                  "markdown_table": markdown_table,
                  "all_passed": all_comments_ok
              }
          }

           Return **EXACTLY** **NONNEGOTIATABLE** only the `test_results` JSON object. Do not use markdown ```json when returning the json. Do not include any explanations, summaries, or additional text.
    model: gpt-4o
    output:
      - test_results
    structured_output: false
    structured_output_dict:
      test_results: dict
    transition: END
