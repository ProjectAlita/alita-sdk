name: "GH11 - Project Issue Workflow"
description: "Test project issue lifecycle: create_issue_on_project, search_project_issues, list_project_issues, update_issue_on_project, comment, close"

toolkits:
  - id: ${GITHUB_TOOLKIT_ID}
    name: ${GITHUB_TOOLKIT_NAME}

state:
  board_repo:
    type: str
    value: ProjectAlita/elitea-testing
  input:
    type: str
  issue_body:
    type: str
  issue_number:
    type: str
  issue_title:
    type: str
  list_result:
    type: str
  messages:
    type: list
  project_number:
    type: int
    value: 11
  project_title:
    type: str
    value: AI_testing_board
  search_query:
    type: str
  search_result:
    type: str
  test_results:
    type: dict
  tool_result:
    type: str
  update_result:
    type: str
  updated_body:
    type: str
  updated_title:
    type: str
entry_point: prepare_issue
nodes:
  - id: prepare_issue
    type: code
    code:
      type: fixed
      value: |
        import time
        import random
        import string

        # Generate unique identifiers
        timestamp = time.strftime('%Y%m%d-%H%M%S')
        random_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))

        # Issue details
        issue_title = f"GH22-Test-{random_id}"
        nl = chr(10)
        issue_body = f"Automated test issue for GH22 Project Issue Workflow.{nl}{nl}**Created:** {timestamp}{nl}**ID:** {random_id}{nl}{nl}This issue will be searched, updated, commented, and closed."

        # Search query to find this specific issue
        search_query = f"GH22-Test-{random_id}"

        {"issue_title": issue_title, "issue_body": issue_body, "search_query": search_query}
    input: []
    output:
      - issue_title
      - issue_body
      - search_query
    structured_output: true
    transition: create_issue_on_project
  - id: create_issue_on_project
    type: toolkit
    input:
      - board_repo
      - project_title
      - issue_title
      - issue_body
    input_mapping:
      board_repo:
        type: variable
        value: board_repo
      body:
        type: variable
        value: issue_body
      project_title:
        type: variable
        value: project_title
      title:
        type: variable
        value: issue_title
    output:
      - tool_result
    structured_output: true
    tool: create_issue_on_project
    toolkit_name: testing
    transition: validate_create
  - id: validate_create
    type: llm
    input:
      - tool_result
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a quality assurance validator.
      task:
        type: fstring
        value: |
          Analyze the output from the 'create_issue_on_project' tool.

          Tool Result: {tool_result}

          Perform the following checks:

          1. Confirm the tool executed successfully (result contains success indicators like "created", "issue with number", or similar).
          2. Extract the issue number from the result (look for patterns like "number 74", "#74", or "number: 74").
          3. Verify that an issue number was found.

          Return a JSON object named test_results with the following structure:

          {{
            "create_issue_ok": boolean (true if creation succeeded),
            "issue_number": string (the extracted issue number, or null if not found)
          }}

          Return **EXACTLY** **NONNEGOTIATABLE** only the JSON object. Do not use markdown ```json when returning the json. Do not include any explanations, summaries, or additional text.
    model: gpt-4o
    output:
      - issue_number
      - test_results
    structured_output: true
    structured_output_dict:
      issue_number: str
      test_results: dict
    transition: search_project_issues
  - id: search_project_issues
    type: toolkit
    input:
      - board_repo
      - project_number
      - search_query
    input_mapping:
      board_repo:
        type: variable
        value: board_repo
      items_count:
        type: fixed
        value: 5
      project_number:
        type: variable
        value: project_number
      search_query:
        type: variable
        value: search_query
    output:
      - search_result
    structured_output: true
    tool: search_project_issues
    toolkit_name: testing
    transition: validate_search
  - id: validate_search
    type: llm
    input:
      - search_result
      - issue_title
      - issue_number
      - test_results
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a quality assurance validator.
      task:
        type: fstring
        value: |
          Analyze the output from the 'search_project_issues' tool.

          Search Result: {search_result}
          Expected Issue Title: {issue_title}
          Expected Issue Number: {issue_number}
          Previous Test Results: {test_results}

          Perform the following checks:

          1. Confirm the search returned results (result is not empty, contains items or data).
          2. Check if the created issue is found in the search results (look for issue title or number).
          3. Count how many items were returned.

          Merge with previous test results and return a JSON object named test_results with the following structure:

          {{
            "create_issue_ok": boolean (from previous results),
            "issue_number": string (from previous results),
            "search_ok": boolean (true if search returned results),
            "issue_found_in_search": boolean (true if our issue was found),
            "search_items_count": integer
          }}

          Return **EXACTLY** **NONNEGOTIATABLE** only the JSON object. Do not use markdown ```json when returning the json. Do not include any explanations, summaries, or additional text.
    model: gpt-4o
    output:
      - test_results
    structured_output: true
    structured_output_dict:
      test_results: dict
    transition: list_project_issues
  - id: list_project_issues
    type: toolkit
    input:
      - board_repo
      - project_number
    input_mapping:
      board_repo:
        type: variable
        value: board_repo
      items_count:
        type: fixed
        value: 10
      project_number:
        type: variable
        value: project_number
    output:
      - list_result
    structured_output: true
    tool: list_project_issues
    toolkit_name: testing
    transition: validate_list
  - id: validate_list
    type: llm
    input:
      - list_result
      - issue_title
      - issue_number
      - test_results
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a quality assurance validator.
      task:
        type: fstring
        value: |
          Analyze the output from the 'list_project_issues' tool.

          List Result: {list_result}
          Expected Issue Title: {issue_title}
          Expected Issue Number: {issue_number}
          Previous Test Results: {test_results}

          Perform the following checks:

          1. Confirm the list returned results (result contains items or data).
          2. Check if the created issue appears in the list (look for issue title or number).
          3. Count how many items were returned.

          Merge with previous test results and return a JSON object named test_results with the following structure:

          {{
            "create_issue_ok": boolean (from previous),
            "issue_number": string (from previous),
            "search_ok": boolean (from previous),
            "issue_found_in_search": boolean (from previous),
            "search_items_count": integer (from previous),
            "list_ok": boolean (true if list returned results),
            "issue_in_list": boolean (true if our issue was found),
            "list_items_count": integer
          }}

          Return **EXACTLY** **NONNEGOTIATABLE** only the JSON object. Do not use markdown ```json when returning the json. Do not include any explanations, summaries, or additional text.
    model: gpt-4o
    output:
      - test_results
    structured_output: true
    structured_output_dict:
      test_results: dict
    transition: prepare_update
  - id: prepare_update
    type: code
    code:
      type: fixed
      value: |
        import time
        import random
        import string

        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
        random_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=4))

        nl = chr(10)
        updated_title = alita_state.get('issue_title', '') + f"-UPDATED-{random_id}"
        updated_body = f"Issue updated by GH22 workflow at {timestamp}.{nl}{nl}Update ID: {random_id}"

        {"updated_title": updated_title, "updated_body": updated_body}
    input:
      - issue_title
    output:
      - updated_title
      - updated_body
    structured_output: true
    transition: update_issue_on_project
  - id: update_issue_on_project
    type: toolkit
    input:
      - board_repo
      - project_title
      - issue_number
      - updated_title
      - updated_body
    input_mapping:
      board_repo:
        type: variable
        value: board_repo
      body:
        type: variable
        value: updated_body
      issue_number:
        type: variable
        value: issue_number
      project_title:
        type: variable
        value: project_title
      title:
        type: variable
        value: updated_title
    output:
      - update_result
    structured_output: true
    tool: update_issue_on_project
    toolkit_name: testing
    transition: validate_update
  - id: validate_update
    type: llm
    input:
      - update_result
      - issue_number
      - issue_title
      - test_results
    input_mapping:
      chat_history:
        type: fixed
        value: []
      system:
        type: fixed
        value: You are a quality assurance validator.
      task:
        type: fstring
        value: |
          Analyze the output from the 'update_issue_on_project' tool and generate final test results.

          Update Result: {update_result}
          Issue Number: {issue_number}
          Issue Title: {issue_title}
          Previous Test Results: {test_results}

          Perform the following checks:

          1. Confirm the update succeeded (result contains "updated", "success", or similar indicators).
          2. Calculate overall test_passed: true if create_issue_ok AND update_ok are both true.

          Merge with previous test results and return a JSON object named test_results with the following structure:

          {{
            "test_passed": boolean (true if core operations passed: create_issue_ok AND update_ok),
            "operations": {{
              "create_issue_on_project": boolean (from test_results.create_issue_ok),
              "search_project_issues": boolean (from test_results.search_ok),
              "list_project_issues": boolean (from test_results.list_ok),
              "update_issue_on_project": boolean (true if update succeeded)
            }},
            "details": {{
              "issue_number": string,
              "issue_title": string,
              "issue_found_in_search": boolean (from test_results),
              "issue_in_list": boolean (from test_results),
              "search_items_count": integer (from test_results),
              "list_items_count": integer (from test_results)
            }}
          }}

          Return **EXACTLY** **NONNEGOTIATABLE** only the JSON object. Do not use markdown ```json when returning the json. Do not include any explanations, summaries, or additional text.
    model: gpt-4o
    output:
      - test_results
    structured_output: false
    structured_output_dict:
      test_results: dict
    transition: END